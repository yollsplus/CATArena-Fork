import requests
import json
import os
import shutil
import time
import glob
import argparse

parser = argparse.ArgumentParser()
parser.add_argument("--model_name", type=str, default="gpt_4_1")
parser.add_argument("--language", type=str, default="")
parser.add_argument("--game_env", type=str, default="gomoku")
parser.add_argument("--game_suffix", type=str, default="gomoku")
parser.add_argument("--game_server", type=str, default="http://127.0.0.1:9000")
parser.add_argument("--dir_path", type=str, default="./gomoku/AI_develop")

# å¾ªç¯èµ›è½®æ¬¡
parser.add_argument("--round_num", type=int, default=1)
# round > 1æ—¶éœ€è¦æä¾›ä¸Šä¸€è½®çš„æ—¥å¿—å’Œcode
parser.add_argument("--log_path", type=str, default=None)
parser.add_argument("--last_round_dir", type=str, default=None)

# LLMç›¸å…³å‚æ•°
parser.add_argument("--llm_api_url", type=str, default="https://az.gptplus5.com/v1/chat/completions", help="LLM APIçš„URL")
parser.add_argument("--llm_api_key", type=str, default="sk-2p51ZI79J5X4OL6S343c17F08f3c432395C711608b2eB0D5", help="LLM APIçš„å¯†é’¥")
parser.add_argument("--llm_model", type=str, default="gpt-4o", help="ä½¿ç”¨çš„LLMæ¨¡å‹")
parser.add_argument("--summary_output_path", type=str, default="./last_round_summary.json", help="LLMæ€»ç»“è¾“å‡ºè·¯å¾„")


args = parser.parse_args()

dir_path = args.dir_path
model_name = args.model_name
language = args.language
game_env = args.game_env
game_suffix = args.game_suffix
round_num = args.round_num
game_server = args.game_server
log_path = args.log_path
last_round_dir = args.last_round_dir
llm_api_url = args.llm_api_url
llm_api_key = args.llm_api_key
llm_model = args.llm_model
summary_output_path = args.summary_output_path


game_env_path = f'./{game_env}'


def call_llm_api(prompt, api_url, api_key, model):
    
    if not api_url or not api_key:
        print("LLM APIæœªé…ç½®ï¼Œè·³è¿‡åˆ†ææ­¥éª¤")
        return None
    
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "model": model,
            "messages": [
                {
                    "role": "system",
                    "content": "You are a Gomoku AI strategy expert. Analyze game data and provide actionable improvement suggestions."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 2000
        }
        
        response = requests.post(api_url, headers=headers, json=data, timeout=120)
        response.raise_for_status()
        
        result = response.json()
        return result['choices'][0]['message']['content']
        
    except Exception as e:
        print(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
        return None


def analyze_tournament_data(csv_path, history_path, code_dir):
    """
    è¯»å–å¹¶åˆ†æä¸Šä¸€è½®çš„æ¯”èµ›æ•°æ®
    
    Args:
        csv_path: CSVæŠ¥å‘Šè·¯å¾„
        history_path: å†å²JSONæ–‡ä»¶è·¯å¾„
        code_dir: ä¸Šä¸€è½®æ‰€æœ‰AIçš„ä»£ç ç›®å½•
    
    Returns:
        åŒ…å«æ•°æ®æ‘˜è¦çš„å­—å…¸
    """
    data_summary = {
        "csv_report": None,
        "history_data": None,
        "ai_codes": {}
    }
    
    # è¯»å–CSVæŠ¥å‘Š
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            csv_content = f.read()
            data_summary["csv_report"] = csv_content
            print(f"  - CSVæŠ¥å‘Šå¤§å°: {len(csv_content)} å­—ç¬¦")
    except Exception as e:
        print(f"è¯»å–CSVæŠ¥å‘Šå¤±è´¥: {e}")
    
    # è¯»å–å®Œæ•´çš„å†å²JSONæ•°æ®
    try:
        with open(history_path, 'r', encoding='utf-8') as f:
            history_data = json.load(f)
            data_summary["history_data"] = history_data
            total_games = history_data.get('total_games', 0)
            print(f"  - å†å²è®°å½•æ€»å±€æ•°: {total_games}")
    except Exception as e:
        print(f"è¯»å–å†å²JSONå¤±è´¥: {e}")
    
    # è¯»å–ä¸Šä¸€è½®æ‰€æœ‰AIçš„ä»£ç 
    try:
        if os.path.exists(code_dir):
            print(f"  - æ‰«æä»£ç ç›®å½•: {code_dir}")
            
            # 1. æ£€æŸ¥æ˜¯å¦æ˜¯æ‰å¹³ç»“æ„ï¼ˆç›´æ¥åŒ…å«ä»£ç æ–‡ä»¶ï¼Œå¦‚ AI_developï¼‰
            # è·å–ç›®å½•ä¸‹æ‰€æœ‰çš„ .py å’Œ .sh æ–‡ä»¶
            root_code_files = [f for f in os.listdir(code_dir) 
                              if os.path.isfile(os.path.join(code_dir, f)) and f.endswith(('.py', '.sh'))]
            
            if root_code_files:
                print(f"    æ£€æµ‹åˆ°æ‰å¹³ç»“æ„ï¼Œå‘ç° {len(root_code_files)} ä¸ªä»£ç æ–‡ä»¶")
                ai_name = "gpt-4o_ai" # é»˜è®¤ä½œä¸ºå½“å‰æ­£åœ¨å¼€å‘çš„AI
                ai_code_files = {}
                
                for file in root_code_files:
                    file_path = os.path.join(code_dir, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                            if len(content) < 50000:  # 50KBé™åˆ¶
                                ai_code_files[file] = content
                    except Exception as e:
                        print(f"    è­¦å‘Š: æ— æ³•è¯»å– {file_path}: {e}")
                
                if ai_code_files:
                    data_summary["ai_codes"][ai_name] = ai_code_files

            # 2. éå†å­ç›®å½• (å…¼å®¹ AI_competitors è¿™ç§å¤šAIåµŒå¥—ç»“æ„)
            for ai_name in os.listdir(code_dir):
                ai_path = os.path.join(code_dir, ai_name)
                if os.path.isdir(ai_path):
                    ai_code_files = {}
                    # è¯»å–è¯¥AIçš„ä¸»è¦ä»£ç æ–‡ä»¶
                    for root, dirs, files in os.walk(ai_path):
                        for file in files:
                            # åªè¯»å–Pythonæ–‡ä»¶å’Œshellè„šæœ¬
                            if file.endswith(('.py', '.sh')):
                                file_path = os.path.join(root, file)
                                rel_path = os.path.relpath(file_path, ai_path)
                                try:
                                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                        content = f.read()
                                        # é™åˆ¶å•ä¸ªæ–‡ä»¶å¤§å°ï¼Œé¿å…è¿‡å¤§
                                        if len(content) < 50000:  # 50KBé™åˆ¶
                                            ai_code_files[rel_path] = content
                                except Exception as e:
                                    print(f"    è­¦å‘Š: æ— æ³•è¯»å– {file_path}: {e}")
                    
                    if ai_code_files:
                        data_summary["ai_codes"][ai_name] = ai_code_files
                        print(f"    - {ai_name}: {len(ai_code_files)} ä¸ªä»£ç æ–‡ä»¶")
        else:
            print(f"  - ä»£ç ç›®å½•ä¸å­˜åœ¨: {code_dir}")
    except Exception as e:
        print(f"è¯»å–AIä»£ç å¤±è´¥: {e}")
    
    return data_summary


def create_llm_analysis_prompt(data_summary):
    """
    åˆ›å»ºç”¨äºLLMåˆ†æçš„æç¤ºè¯
    
    Args:
        data_summary: æ•°æ®æ‘˜è¦å­—å…¸
    
    Returns:
        æç¤ºè¯å­—ç¬¦ä¸²
    """
    prompt = """# Gomoku AI Tournament Analysis

Analyze the previous round data and suggest improvements for gpt-4o_ai.

## Tournament Stats

"""
    
    if data_summary.get("csv_report"):
        prompt += f"```csv\n{data_summary['csv_report']}\n```\n\n"
    
    prompt += """## Game History

"""
    
    if data_summary.get("history_data"):
        history_json = json.dumps(data_summary['history_data'], indent=2, ensure_ascii=False)
        prompt += f"```json\n{history_json}\n```\n\n"
    
    prompt += """## AI Code Implementations

"""
    
    if data_summary.get("ai_codes"):
        for ai_name, code_files in data_summary["ai_codes"].items():
            prompt += f"\n### {ai_name}\n\n"
            for file_path, content in code_files.items():
                prompt += f"**{file_path}**:\n```python\n{content}\n```\n\n"
    
    prompt += """## Analysis Task

You are a Code Reviewer for the **gpt-4o_ai** project.
Your goal is to guide the developer (Agent) on how to refactor the code to win.

**DO NOT write the full code implementation.**
**DO NOT focus only on high-level tactics (like "play aggressively").**

Instead, analyze the **gpt-4o_ai** source code provided above and point out specific logical flaws or missing features that caused the losses.

Please structure your analysis as follows:

1. **Codebase Diagnosis**:
   - Identify which specific functions or logic blocks in `gpt-4o_ai` are responsible for the poor performance.
   - Example: "The `score_position` function fails to detect broken-4 patterns because the regex `11011` is missing."
   - Example: "The search depth in `minimax` is hardcoded to 1, which is insufficient."

2. **Architectural Suggestions**:
   - Suggest specific algorithmic improvements (e.g., "Implement Alpha-Beta pruning", "Add Zobrist hashing").
   - Explain *how* these changes should be integrated into the existing class structure.

3. **Prioritized Refactoring Plan**:
   - List 3 concrete coding tasks for the Agent to perform in the next iteration.
   - Example: "1. Modify `evaluate_board` to increase weight for opponent's open-3."
"""
    
    return prompt


def summarize_with_llm(csv_path, history_path, code_dir, api_url, api_key, model):
    """
    ä½¿ç”¨LLMæ€»ç»“ä¸Šä¸€è½®çš„æ¯”èµ›æ•°æ®
    
    Args:
        csv_path: CSVæŠ¥å‘Šè·¯å¾„
        history_path: å†å²JSONæ–‡ä»¶è·¯å¾„
        code_dir: ä¸Šä¸€è½®æ‰€æœ‰AIçš„ä»£ç ç›®å½•
        api_url: LLM API URL
        api_key: LLM API Key
        model: LLMæ¨¡å‹åç§°
    
    Returns:
        ç»“æ„åŒ–çš„æ€»ç»“æ•°æ®ï¼ˆå­—å…¸æ ¼å¼ï¼‰
    """
    print("=" * 60)
    print("å¼€å§‹ä½¿ç”¨LLMåˆ†æä¸Šä¸€è½®æ¯”èµ›æ•°æ®...")
    print("=" * 60)
    
    # 1. æ”¶é›†å¹¶è¯»å–å®Œæ•´æ•°æ®ï¼ˆåŒ…æ‹¬æ‰€æœ‰AIçš„ä»£ç ï¼‰
    print("\n[1/3] è¯»å–å®Œæ•´æ¯”èµ›æ•°æ®å’ŒAIä»£ç ...")
    data_summary = analyze_tournament_data(csv_path, history_path, code_dir)
    
    # 2. åˆ›å»ºåˆ†ææç¤ºè¯
    print("\n[2/3] åˆ›å»ºLLMåˆ†ææç¤ºè¯...")
    analysis_prompt = create_llm_analysis_prompt(data_summary)
    
    # å¯é€‰ï¼šä¿å­˜æç¤ºè¯ä»¥ä¾›è°ƒè¯•
    prompt_debug_path = summary_output_path.replace('.json', '_prompt.txt')
    with open(prompt_debug_path, 'w', encoding='utf-8') as f:
        f.write(analysis_prompt)
    print(f"  - æç¤ºè¯å·²ä¿å­˜åˆ°: {prompt_debug_path}")
    
    # 3. è°ƒç”¨LLMè¿›è¡Œåˆ†æ
    print(f"\n[3/3] è°ƒç”¨LLM API ({model}) è¿›è¡Œåˆ†æ...")
    llm_response = call_llm_api(analysis_prompt, api_url, api_key, model)
    
    if llm_response is None:
        print("  - LLMåˆ†æå¤±è´¥ï¼Œè¿”å›ç©ºæ€»ç»“")
        return None
    
    # 4. ç›´æ¥ä¿å­˜LLMå“åº”æ–‡æœ¬ï¼ˆä¸è§£æJSONï¼‰
    try:
        # LLMè¿”å›çš„æ˜¯è‡ªç„¶è¯­è¨€åˆ†æï¼Œç›´æ¥ä½œä¸ºraw_analysisä¿å­˜
        summary_data = {
            "raw_analysis": llm_response,
            "note": "LLM strategy analysis in natural language"
        }
        
        # ä¿å­˜æ€»ç»“
        with open(summary_output_path, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n[SUCCESS] LLMåˆ†æå®Œæˆï¼æ€»ç»“å·²ä¿å­˜åˆ°: {summary_output_path}")
        print(f"  - åˆ†æé•¿åº¦: {len(llm_response)} å­—ç¬¦")
        print("=" * 60)
        
        return summary_data
        
    except Exception as e:
        print(f"  - ä¿å­˜LLMå“åº”å¤±è´¥: {e}")
        # ä¿å­˜åŸå§‹å“åº”ä»¥ä¾›è°ƒè¯•
        raw_output_path = summary_output_path.replace('.json', '_raw.txt')
        with open(raw_output_path, 'w', encoding='utf-8') as f:
            f.write(llm_response)
        print(f"  - åŸå§‹å“åº”å·²ä¿å­˜åˆ°: {raw_output_path}")
        return None


# æ„å»ºåŸºç¡€æç¤ºè¯
# æ³¨æ„: ChatPromptWithLlm.py åªåœ¨ Round 2+ è¢«è°ƒç”¨ (å½“ use_llm_summary=true æ—¶)
# Round 1 å§‹ç»ˆä½¿ç”¨ ChatPrompt.py
if round_num == 1:
    raise ValueError("ChatPromptWithLlm.py should not be called for Round 1. Use ChatPrompt.py instead.")

# Round 2+: åŸºäºä¸Šä¸€è½®ä¼˜åŒ–ç­–ç•¥
# å…ˆå ä½ï¼Œåé¢ä¼šæ’å…¥LLMåˆ†æ
prompt_header = f'''
# Round {round_num}: Improve Your Gomoku AI Strategy

##YOUR MISSION: 
**You MUST call `edit_file` to improve `{dir_path}/ai_service.py` based on the expert analysis below.**

'''

prompt_footer = f'''

##ACTION STEPS:

**STEP 1**: Read your current strategy
```python
read_text_file('{last_round_dir}/ai_service.py')
```

**STEP 2**: Analyze the problems identified above

**STEP 3**: Call `edit_file` NOW to implement improvements
```python
edit_file('{dir_path}/ai_service.py', {{
  "oldText": "...exact code from current strategy...",
  "newText": "...improved code based on analysis..."
}})
```

##CRITICAL REQUIREMENTS:
- You MUST call `edit_file` - don't just read files and stop
- Focus on the specific issues mentioned in the analysis
- Improve threat detection, pattern recognition, and position scoring
- Keep correct indentation (4 spaces per level)
- Use existing helper functions (don't create new ones)

## â›” COMMON MISTAKES TO AVOID (READ CAREFULLY)

1.  **Calling Undefined Functions**:
    - **ERROR**: `if self._detect_pattern(...)` (when `_detect_pattern` is NOT defined in the class).
    - **FIX**: You MUST define any helper function you use.
    - **HOW**: Since `replace_python_method` only replaces ONE method, you should define helper functions **inside** `select_best_move` as nested functions.
    - **Example**:
      ```python
      def select_best_move(self, board, ...):
          def _my_helper(x, y):  # Define it HERE
              return ...
          
          # Now you can use it
          val = _my_helper(1, 2)
      ```

2.  **Unreachable Code (Early Return)**:
    - **ERROR**:
      ```python
      if best_move:
          return best_move  # <--- RETURNS HERE
      
      # Minimax code below is NEVER REACHED!
      def minimax(...): ...
      ```
    - **FIX**: Remove the early return if you want to run further logic (like Minimax). Only return when you have the FINAL result.

3.  **Syntax Errors**:
    - Ensure all parentheses are closed.
    - Ensure indentation is consistent (4 spaces).

## ğŸ› ï¸ TOOL USAGE TIP:
Use `replace_python_method` instead of `edit_file` for safer editing.
It automatically handles indentation for you!

Example:
```python
replace_python_method(
    path='{dir_path}/ai_service.py',
    class_name='GomokuAI',
    method_name='select_best_move',
    new_code=\'\'\'def select_best_move(self, board, my_color, opponent_color):
    # Define helpers inside
    def evaluate(x, y):
        return 0
        
    # Your logic
    # ...
    return best_move\'\'\'
)
```

**START NOW - Read the code, then call replace_python_method to improve it!**
'''.strip()

# åˆå§‹åŒ– prompt_dataï¼ˆåé¢ä¼šæ’å…¥åˆ†æå†…å®¹ï¼‰
prompt_data = prompt_header


# å¤„ç†å¤šè½®å­¦ä¹ 
if round_num > 1:
    assert os.path.exists(last_round_dir), f"ä¸Šä¸€è½®çš„ä»£ç ä¸å­˜åœ¨: {last_round_dir}"
    
    # æ‰¾åˆ°ä¸Šä¸€è½®çš„æ—¥å¿—æ–‡ä»¶
    last_round_log_dir = glob.glob(os.path.join(log_path, f'tournament_report_history_*.json'))
    last_round_log_dir = sorted(last_round_log_dir, key=lambda x: int(x.split('_')[-1].split('.')[0]))[-1]
    
    last_round_info = glob.glob(os.path.join(log_path, f'tournament_report_tournament_*.csv'))
    last_round_info = sorted(last_round_info, key=lambda x: int(x.split('_')[-1].split('.')[0]))[-1]
    
    assert os.path.exists(last_round_log_dir), f"ä¸Šä¸€è½®çš„æ—¥å¿—ä¸å­˜åœ¨: {last_round_log_dir}"
    assert os.path.exists(last_round_info), f"ä¸Šä¸€è½®çš„æŠ¥å‘Šä¸å­˜åœ¨: {last_round_info}"
    
    print("=" * 60)
    print(f"æ£€æµ‹åˆ°ç¬¬ {round_num} è½®ï¼Œå¼€å§‹åˆ†æä¸Šä¸€è½®æ•°æ®...")
    print(f"  - CSVæŠ¥å‘Š: {last_round_info}")
    print(f"  - å†å²è®°å½•: {last_round_log_dir}")
    print(f"  - ä»£ç ç›®å½•: {last_round_dir}")
    print("=" * 60)
    
    # ä½¿ç”¨LLMåˆ†ææ€»ç»“
    llm_summary = summarize_with_llm(
        csv_path=last_round_info,
        history_path=last_round_log_dir,
        code_dir=last_round_dir,
        api_url=llm_api_url,
        api_key=llm_api_key,
        model=llm_model
    )
    
    # å°†LLMæ€»ç»“æ·»åŠ åˆ°æç¤ºè¯ä¸­ï¼ˆæ”¾åœ¨æœ€å‰é¢ï¼Œç¡®ä¿Agentå…ˆçœ‹åˆ°åˆ†æï¼‰
    if llm_summary:
        # å¦‚æœæœ‰raw_analysiså­—æ®µï¼Œç›´æ¥ç”¨åŸå§‹æ–‡æœ¬
        if isinstance(llm_summary, dict) and "raw_analysis" in llm_summary:
            analysis_text = llm_summary["raw_analysis"]
        else:
            # å¦åˆ™è½¬ä¸ºJSON
            analysis_text = json.dumps(llm_summary, indent=2, ensure_ascii=False)
        
        # åˆ†ææ”¾åœ¨æœ€å‰é¢
        prompt_data += f"\n##Expert Analysis from Last Round\n\n{analysis_text}\n"
    else:
        print("\n[WARNING] LLMåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®å¼•ç”¨æ–¹å¼...")
        prompt_data += f"\n##Tournament Data (Analyze This)\n- Report: {last_round_info}\n- History: {last_round_log_dir}\n- Previous code: {last_round_dir}\n"
    
    # æ·»åŠ æ‰§è¡ŒæŒ‡ä»¤ï¼ˆfooterï¼‰
    prompt_data += prompt_footer

# æ·»åŠ è¯­è¨€è¦æ±‚
if language:
    prompt_data += f"\n{language} is the language you should use to develop your AI service."

# è¾“å‡ºæœ€ç»ˆæç¤ºè¯
print("\n" + "=" * 60)
print("æœ€ç»ˆæç¤ºè¯:")
print("=" * 60)
print(prompt_data)
